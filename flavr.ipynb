{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_video/blob/main/flavr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh5WOG60RIHN"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import importlib.util\n",
        "from google.colab import files\n",
        "import torch\n",
        "\n",
        "if 'downloaded_model_type' not in globals():\n",
        "    downloaded_model_type = None\n",
        "\n",
        "model_type = \"2x\"  #@param [\"2x\", \"4x\", \"8x\"]\n",
        "\n",
        "print(f\"Current PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "print(\"Installing FLAVR dependencies...\")\n",
        "\n",
        "print(\"Installing numpy...\")\n",
        "result_numpy = subprocess.run([\"pip\", \"install\", \"numpy==1.23.5\"], capture_output=True, text=True)\n",
        "if result_numpy.returncode != 0:\n",
        "    print(\"Error installing numpy:\")\n",
        "    print(result_numpy.stderr)\n",
        "\n",
        "print(\"Installing opencv-python...\")\n",
        "result_opencv = subprocess.run([\"pip\", \"install\", \"opencv-python==4.8.0.76\"], capture_output=True, text=True)\n",
        "if result_opencv.returncode != 0:\n",
        "    print(\"Error installing opencv-python:\")\n",
        "    print(result_opencv.stderr)\n",
        "\n",
        "print(\"Installing PyAV...\")\n",
        "result_av = subprocess.run([\"pip\", \"install\", \"av==10.0.0\"], capture_output=True, text=True)\n",
        "if result_av.returncode != 0:\n",
        "    print(\"Error installing PyAV:\")\n",
        "    print(result_av.stderr)\n",
        "\n",
        "if importlib.util.find_spec(\"av\") is not None:\n",
        "    import av\n",
        "    print(f\"PyAV successfully installed, version: {av.__version__}\")\n",
        "else:\n",
        "    print(\"Error: PyAV is not installed after installation attempt.\")\n",
        "\n",
        "if not os.path.exists(\"/content/FLAVR\"):\n",
        "    print(\"Cloning FLAVR repository...\")\n",
        "    result_git = subprocess.run([\"git\", \"clone\", \"https://github.com/tarun005/FLAVR.git\", \"/content/FLAVR\"], capture_output=True, text=True)\n",
        "    if result_git.returncode != 0:\n",
        "        print(\"Error cloning repository:\")\n",
        "        print(result_git.stderr)\n",
        "    else:\n",
        "        print(\"Repository successfully cloned.\")\n",
        "else:\n",
        "    print(\"FLAVR repository already exists.\")\n",
        "\n",
        "model_urls = {\n",
        "    \"2x\": \"1IZe-39ZuXy3OheGJC-fT3shZocGYuNdH\",\n",
        "    \"4x\": \"1xoZqWJdIOjSaE2DtH4ifXKlRwFySm5Gq\",\n",
        "    \"8x\": \"1DlXgNANDGLZEYOCMvQ5T1cAqkW90FiPt\"\n",
        "}\n",
        "model_path = f\"/content/FLAVR_{model_type}.pth\"\n",
        "\n",
        "if os.path.exists(model_path) and downloaded_model_type == model_type:\n",
        "    print(f\"Model {model_type} is already downloaded and matches the selected type: {model_path}\")\n",
        "elif os.path.exists(model_path) and downloaded_model_type != model_type:\n",
        "    print(f\"Model {downloaded_model_type} already exists, but {model_type} is selected. Replacing model...\")\n",
        "    os.remove(model_path)\n",
        "    download_required = True\n",
        "else:\n",
        "    print(f\"Model {model_type} is missing. Download required.\")\n",
        "    download_required = True\n",
        "\n",
        "if download_required:\n",
        "    print(f\"Downloading FLAVR model {model_type}...\")\n",
        "    subprocess.run([\"pip\", \"install\", \"gdown\"], capture_output=True, text=True)\n",
        "    result_gdown = subprocess.run([\"gdown\", f\"https://drive.google.com/uc?id={model_urls[model_type]}\", \"-O\", model_path], capture_output=True, text=True)\n",
        "\n",
        "    if result_gdown.returncode == 0 and os.path.exists(model_path):\n",
        "        global downloaded_model_type\n",
        "        downloaded_model_type = model_type\n",
        "        print(f\"Model {model_type} successfully downloaded to {model_path}\")\n",
        "    else:\n",
        "        print(f\"Error: Failed to automatically download model {model_type}.\")\n",
        "        print(result_gdown.stderr)\n",
        "        print(\"Please download the model manually:\")\n",
        "        print(f\"1. Use the link: https://drive.google.com/file/d/{model_urls[model_type]}/view\")\n",
        "        print(f\"2. Download the file and upload it below with the name FLAVR_{model_type}.pth\")\n",
        "        uploaded = files.upload()\n",
        "        for uploaded_file_name, _ in uploaded.items():\n",
        "            if uploaded_file_name.endswith(\".pth\"):\n",
        "                os.rename(uploaded_file_name, model_path)\n",
        "                downloaded_model_type = model_type\n",
        "                print(f\"Model saved as {model_path}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Error: Uploaded file is not a .pth model.\")\n",
        "\n",
        "# change /content/FLAVR/interpolate.py\n",
        "with open('/content/FLAVR/interpolate.py', 'w') as f:\n",
        "    f.write('''import os\n",
        "import torch\n",
        "import cv2\n",
        "import time\n",
        "import sys\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from torchvision.io import read_video\n",
        "from dataset.transforms import ToTensorVideo, Resize\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input_video\", type=str, required=True, help=\"Path/URL to input video\")\n",
        "parser.add_argument(\"--youtube-dl\", type=str, help=\"Path to youtube_dl\", default=\".local/bin/youtube-dl\")\n",
        "parser.add_argument(\"--factor\", type=int, required=True, choices=[2, 4, 8], help=\"Interpolation factor: 2x/4x/8x\")\n",
        "parser.add_argument(\"--codec\", type=str, help=\"Video codec\", default=\"mpeg4\")\n",
        "parser.add_argument(\"--load_model\", required=True, type=str, help=\"Path to saved model\")\n",
        "parser.add_argument(\"--up_mode\", type=str, help=\"Upscale mode\", default=\"transpose\")\n",
        "parser.add_argument(\"--output_ext\", type=str, help=\"Output video format\", default=\".avi\")\n",
        "parser.add_argument(\"--input_ext\", type=str, help=\"Input video format\", default=\".mp4\")\n",
        "parser.add_argument(\"--downscale\", type=float, help=\"Downscale for memory saving\", default=1)\n",
        "parser.add_argument(\"--output_fps\", type=int, help=\"Target FPS\", default=30)\n",
        "parser.add_argument(\"--batch_size\", type=int, help=\"Batch size\", default=1)\n",
        "parser.add_argument(\"--is_folder\", action=\"store_true\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "input_video = args.input_video\n",
        "input_ext = args.input_ext\n",
        "\n",
        "from os import path\n",
        "\n",
        "if not args.is_folder and not path.exists(input_video):\n",
        "    print(\"Invalid input file path!\")\n",
        "    exit()\n",
        "\n",
        "if args.is_folder and not path.exists(input_video):\n",
        "    print(\"Invalid input folder path!\")\n",
        "    exit()\n",
        "\n",
        "if args.output_ext != \".avi\":\n",
        "    print(\"Only .avi output is supported for now. Use ffmpeg to convert to mp4 or other formats.\")\n",
        "\n",
        "if input_video.endswith(\"/\"):\n",
        "    video_name = input_video.split(\"/\")[-2].split(input_ext)[0]\n",
        "else:\n",
        "    video_name = input_video.split(\"/\")[-1].split(input_ext)[0]\n",
        "\n",
        "output_video = os.path.join(video_name + f\"_{args.factor}x\" + str(args.output_ext))\n",
        "\n",
        "n_outputs = args.factor - 1\n",
        "model_name = \"unet_18\"\n",
        "nbr_frame = 4\n",
        "joinType = \"concat\"\n",
        "\n",
        "if input_video.startswith(\"http\"):\n",
        "    assert args.youtube_dl is not None\n",
        "    youtube_dl_path = args.youtube_dl\n",
        "    cmd = f\"{youtube_dl_path} -i -o video.mp4 {input_video}\"\n",
        "    os.system(cmd)\n",
        "    input_video = \"video.mp4\"\n",
        "    output_video = \"video\" + str(args.output_ext)\n",
        "\n",
        "def loadModel(model, checkpoint):\n",
        "    saved_state_dict = torch.load(checkpoint)['state_dict']\n",
        "    saved_state_dict = {k.partition(\"module.\")[-1]:v for k,v in saved_state_dict.items()}\n",
        "    model.load_state_dict(saved_state_dict)\n",
        "\n",
        "checkpoint = args.load_model\n",
        "from model.FLAVR_arch import UNet_3D_3D\n",
        "\n",
        "model = UNet_3D_3D(model_name.lower(), n_inputs=4, n_outputs=n_outputs, joinType=joinType, upmode=args.up_mode)\n",
        "loadModel(model, checkpoint)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "model = model.cuda()\n",
        "\n",
        "print(\"Warming up model...\")\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    dummy_input = [torch.randn(args.batch_size, 3, 424, 568).cuda() for _ in range(nbr_frame)]\n",
        "    model(dummy_input)\n",
        "print(\"Warmup complete.\")\n",
        "\n",
        "def write_video_cv2(frames, video_name, fps, sizes):\n",
        "    out = cv2.VideoWriter(video_name, cv2.CAP_OPENCV_MJPEG, cv2.VideoWriter_fourcc('M','J','P','G'), fps, sizes)\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "\n",
        "def make_image(img):\n",
        "    q_im = img.data.mul(255.).clamp(0, 255).round()\n",
        "    im = q_im.permute(1, 2, 0).cpu().numpy().astype(np.uint8)\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)\n",
        "    return im\n",
        "\n",
        "def files_to_videoTensor(path, downscale=1.):\n",
        "    from PIL import Image\n",
        "    files = sorted(os.listdir(path))\n",
        "    print(f\"Files found: {len(files)}\")\n",
        "    images = [torch.Tensor(np.asarray(Image.open(os.path.join(input_video, f)))).type(torch.uint8) for f in files]\n",
        "    print(f\"Image size: {images[0].shape}\")\n",
        "    videoTensor = torch.stack(images)\n",
        "    return videoTensor\n",
        "\n",
        "def video_to_tensor(video):\n",
        "    videoTensor, _, md = read_video(video, pts_unit='sec')\n",
        "    fps = md[\"video_fps\"]\n",
        "    print(f\"Video FPS: {fps}\")\n",
        "    return videoTensor\n",
        "\n",
        "def video_transform(videoTensor, downscale=1):\n",
        "    T, H, W = videoTensor.size(0), videoTensor.size(1), videoTensor.size(2)\n",
        "    downscale = int(downscale * 8)\n",
        "    resizes = 8 * (H // downscale), 8 * (W // downscale)\n",
        "    transforms = torchvision.transforms.Compose([ToTensorVideo(), Resize(resizes)])\n",
        "    videoTensor = transforms(videoTensor)\n",
        "    print(f\"Resizing to {resizes[0]}x{resizes[1]}\")\n",
        "    return videoTensor, resizes\n",
        "\n",
        "if args.is_folder:\n",
        "    videoTensor = files_to_videoTensor(input_video, args.downscale)\n",
        "else:\n",
        "    videoTensor = video_to_tensor(input_video)\n",
        "\n",
        "idxs = torch.Tensor(range(len(videoTensor))).type(torch.long).view(1, -1).unfold(1, size=nbr_frame, step=1).squeeze(0)\n",
        "videoTensor, resizes = video_transform(videoTensor, args.downscale)\n",
        "\n",
        "frames = torch.unbind(videoTensor, 1)\n",
        "n_inputs = len(frames)\n",
        "width = n_outputs + 1\n",
        "\n",
        "outputs = []\n",
        "outputs.append(frames[idxs[0][1]])\n",
        "\n",
        "model = model.eval()\n",
        "\n",
        "batch_size = args.batch_size\n",
        "\n",
        "for i in tqdm.tqdm(range(0, len(idxs), batch_size)):\n",
        "    batch_idxs = idxs[i:i + batch_size]\n",
        "    inputs = []\n",
        "    for idx_set in batch_idxs:\n",
        "        input_set = [frames[idx_].cuda().unsqueeze(0) for idx_ in idx_set]\n",
        "        inputs.append(input_set)\n",
        "\n",
        "    batch_inputs = []\n",
        "    for j in range(nbr_frame):\n",
        "        batch_inputs.append(torch.cat([inputs[k][j] for k in range(len(inputs))], dim=0))\n",
        "\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "        outputFrame = model(batch_inputs)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    temp_outputs = []\n",
        "    for batch_idx in range(len(batch_idxs)):\n",
        "        for output_idx in range(len(outputFrame)):\n",
        "            temp_outputs.append(outputFrame[output_idx][batch_idx].to('cpu', non_blocking=True))\n",
        "        temp_outputs.append(batch_inputs[2][batch_idx].squeeze(0).to('cpu', non_blocking=True))\n",
        "    outputs.extend(temp_outputs)\n",
        "\n",
        "new_video = [make_image(im_) for im_ in outputs]\n",
        "write_video_cv2(new_video, output_video, args.output_fps, (resizes[1], resizes[0]))\n",
        "\n",
        "print(\"Saving to\", output_video.split(\".\")[0] + \".mp4\")\n",
        "os.system('ffmpeg -hide_banner -loglevel warning -i %s %s' % (output_video, output_video.split(\".\")[0] + \".mp4\"))\n",
        "os.remove(output_video)\n",
        "''')\n",
        "\n",
        "print(\"File /content/FLAVR/interpolate.py has been updated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5jtbSVEyDg_"
      },
      "outputs": [],
      "source": [
        "#@title ##**Select Video File** { display-mode: \"form\" }\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "upload_option = \"Upload from PC\"  #@param [\"Upload from PC\", \"Load from Google Drive Root\", \"Load from Google Drive\"]\n",
        "\n",
        "file_name = None\n",
        "last_selected_button = None\n",
        "\n",
        "def reset_button_colors(buttons):\n",
        "    for btn in buttons:\n",
        "        btn.style.button_color = None\n",
        "\n",
        "if upload_option == \"Upload from PC\":\n",
        "    print(\"Please upload a video file.\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "        file_name = None\n",
        "\n",
        "elif upload_option == \"Load from Google Drive Root\":\n",
        "    drive.mount('/content/drive')\n",
        "    root_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "    video_extensions = ['.mp4', '.mkv', '.avi', '.mov']\n",
        "    files_list = []\n",
        "\n",
        "    for f in os.listdir(root_dir):\n",
        "        if os.path.isfile(os.path.join(root_dir, f)) and os.path.splitext(f)[1].lower() in video_extensions:\n",
        "            files_list.append(f)\n",
        "\n",
        "    if not files_list:\n",
        "        print(\"No video files found in Google Drive root.\")\n",
        "        file_name = None\n",
        "    else:\n",
        "        print(\"Select a video file from Google Drive root:\")\n",
        "\n",
        "        output = widgets.Output()\n",
        "        buttons = []\n",
        "\n",
        "        def on_button_clicked(b):\n",
        "            global file_name, last_selected_button\n",
        "            with output:\n",
        "                clear_output()\n",
        "                reset_button_colors(buttons)\n",
        "                selected_file = b.description\n",
        "                file_name = os.path.join(root_dir, selected_file)\n",
        "\n",
        "                if file_name and os.path.exists(file_name):\n",
        "                    b.style.button_color = 'green'\n",
        "                else:\n",
        "                    b.style.button_color = 'red'\n",
        "\n",
        "                last_selected_button = b\n",
        "                print(f\"Selected file: {file_name if file_name else 'None'}\")\n",
        "\n",
        "        for file in files_list:\n",
        "            button = widgets.Button(description=file, layout=widgets.Layout(width='500px', overflow='hidden', text_overflow='ellipsis'))\n",
        "            button.on_click(on_button_clicked)\n",
        "            buttons.append(button)\n",
        "\n",
        "        display(widgets.VBox(buttons), output)\n",
        "\n",
        "elif upload_option == \"Load from Google Drive\":\n",
        "    drive.mount('/content/drive')\n",
        "    root_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "    video_extensions = ['.mp4', '.mkv', '.avi', '.mov']\n",
        "    files_list = []\n",
        "\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f in filenames:\n",
        "            if os.path.splitext(f)[1].lower() in video_extensions:\n",
        "                relative_path = os.path.relpath(os.path.join(dirpath, f), root_dir)\n",
        "                files_list.append(relative_path)\n",
        "\n",
        "    if not files_list:\n",
        "        print(\"No video files found in Google Drive or its subfolders.\")\n",
        "        file_name = None\n",
        "    else:\n",
        "        print(\"Select a video file from Google Drive (including subfolders):\")\n",
        "\n",
        "        output = widgets.Output()\n",
        "        buttons = []\n",
        "\n",
        "        def on_button_clicked(b):\n",
        "            global file_name, last_selected_button\n",
        "            with output:\n",
        "                clear_output()\n",
        "                reset_button_colors(buttons)\n",
        "                selected_file = b.description\n",
        "                file_name = os.path.join(root_dir, selected_file)\n",
        "\n",
        "                if file_name and os.path.exists(file_name):\n",
        "                    b.style.button_color = 'green'\n",
        "                else:\n",
        "                    b.style.button_color = 'red'\n",
        "\n",
        "                last_selected_button = b\n",
        "                print(f\"Selected file: {file_name if file_name else 'None'}\")\n",
        "\n",
        "        for file in files_list:\n",
        "            button = widgets.Button(description=file, layout=widgets.Layout(width='500px', overflow='hidden', text_overflow='ellipsis'))\n",
        "            button.on_click(on_button_clicked)\n",
        "            buttons.append(button)\n",
        "\n",
        "        display(widgets.VBox(buttons), output)\n",
        "\n",
        "if file_name:\n",
        "    print(f\"Video file path set to: {file_name}\")\n",
        "else:\n",
        "    print(\"Video file path not set. Please select a file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK3y6GasSI3v"
      },
      "outputs": [],
      "source": [
        "#@title ##**Config** { display-mode: \"form\" }\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "interpolation_factor = 2  #@param {type:\"slider\", min:2, max:8, step:2}\n",
        "segment_duration = 3  #@param {type:\"slider\", min:1, max:60, step:1}\n",
        "batch_size = 1  #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "\n",
        "#path\n",
        "output_folder = \"google_drive\" #@param [\"google_drive\",\"root\"]\n",
        "\n",
        "if output_folder == \"google_drive\":\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "#clear\n",
        "\n",
        "clear_input_folder = False #@param {type:\"boolean\"}\n",
        "flavr_input_folder = '/content/drive/MyDrive/temp_segments'\n",
        "\n",
        "if clear_input_folder:\n",
        "    if os.path.isdir(flavr_input_folder):\n",
        "        shutil.rmtree(flavr_input_folder)\n",
        "    os.makedirs(flavr_input_folder)\n",
        "\n",
        "clear_output_folder = False #@param {type:\"boolean\"}\n",
        "flavr_output_folder = '/content/drive/MyDrive/output_segments'\n",
        "\n",
        "if clear_output_folder:\n",
        "    if os.path.isdir(flavr_output_folder):\n",
        "        shutil.rmtree(flavr_output_folder)\n",
        "    os.makedirs(flavr_output_folder)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run** { display-mode: \"form\" }\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import logging\n",
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "if 'file_name' not in globals() or file_name is None or not os.path.exists(file_name):\n",
        "    print(\"Error: Video file not selected or does not exist. Run the 'Select video file' cell.\")\n",
        "else:\n",
        "    print(f\"Increasing FPS for video: {file_name}\")\n",
        "    print(f\"Input file size: {os.path.getsize(file_name) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    log_file = '/content/processing_log.txt'\n",
        "    if os.path.exists(log_file):\n",
        "        os.remove(log_file)\n",
        "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
        "                       format='%(asctime)s - %(message)s')\n",
        "\n",
        "    if output_folder == \"google_drive\":\n",
        "        drive.mount('/content/drive')\n",
        "        temp_dir = \"/content/drive/MyDrive/temp_segments\"\n",
        "        output_segments_dir = \"/content/drive/MyDrive/output_segments\"\n",
        "    else:\n",
        "        temp_dir = \"/content/temp_segments\"\n",
        "        output_segments_dir = \"/content/output_segments\"\n",
        "\n",
        "    def count_segments(directory):\n",
        "        for attempt in range(20):\n",
        "            try:\n",
        "                if os.path.exists(directory):\n",
        "                    return len([f for f in os.listdir(directory) if f.endswith(\".mp4\")])\n",
        "                return 0\n",
        "            except Exception as e:\n",
        "                if attempt < 19:\n",
        "                    time.sleep(3)\n",
        "                    continue\n",
        "                print(f\"Failed to count segments in {directory} after 20 attempts: {str(e)}\")\n",
        "                return 0\n",
        "\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "    os.makedirs(output_segments_dir, exist_ok=True)\n",
        "\n",
        "    existing_input_segments = count_segments(temp_dir)\n",
        "    existing_output_segments = count_segments(output_segments_dir)\n",
        "    print(f\"Segments to process (temp_segments): {existing_input_segments}\")\n",
        "    print(f\"Processed segments (output_segments): {existing_output_segments}\")\n",
        "\n",
        "    cmd_bitrate = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=bit_rate\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", file_name]\n",
        "    result_bitrate = subprocess.run(cmd_bitrate, capture_output=True, text=True)\n",
        "    input_bitrate = int(result_bitrate.stdout.strip()) if result_bitrate.stdout.strip().isdigit() else 2000000\n",
        "    output_bitrate = input_bitrate * interpolation_factor\n",
        "    logging.info(f\"Input video bitrate: {input_bitrate} bps, Output bitrate for all segments: {output_bitrate} bps\")\n",
        "\n",
        "    cap = cv2.VideoCapture(file_name)\n",
        "    input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    input_duration = frame_count / input_fps\n",
        "    output_fps = input_fps * interpolation_factor\n",
        "    expected_frame_count = frame_count * interpolation_factor\n",
        "    cap.release()\n",
        "    print(f\"Input FPS: {input_fps}, Frames: {frame_count}, Duration: {input_duration:.2f} sec\")\n",
        "    print(f\"Target FPS: {output_fps}, Expected frames: {expected_frame_count}, Expected duration: {input_duration:.2f} sec\")\n",
        "\n",
        "    base_file_name = os.path.basename(file_name)\n",
        "    output_file_name = base_file_name.rsplit('.', 1)[0] + f'_{interpolation_factor}x.mp4'\n",
        "    if output_folder == \"google_drive\":\n",
        "        save_path = '/content/drive/MyDrive/'\n",
        "    elif output_folder == \"root\":\n",
        "        save_path = '/content/'\n",
        "    else:\n",
        "        save_path = '/content/'\n",
        "    output_video = os.path.join(save_path, output_file_name)\n",
        "    temp_output_video = os.path.join(save_path, \"temp_\" + output_file_name)\n",
        "\n",
        "    model_path = f\"/content/FLAVR_{model_type}.pth\"\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Error: model not found at {model_path}. Run the 'Install FLAVR dependencies' cell.\")\n",
        "    elif not os.path.exists(\"/content/FLAVR/interpolate.py\"):\n",
        "        print(\"Error: interpolate.py script not found. Make sure the FLAVR repository is downloaded.\")\n",
        "    else:\n",
        "        stats_file = os.path.join(temp_dir, \"processing_stats.json\")\n",
        "        if os.path.exists(stats_file):\n",
        "            with open(stats_file, 'r') as f:\n",
        "                stats = json.load(f)\n",
        "                total_flavr_time = stats.get('total_flavr_time', 0)\n",
        "                total_batches = stats.get('total_batches', 0)\n",
        "                processed_duration = stats.get('processed_duration', 0)\n",
        "        else:\n",
        "            total_flavr_time = 0\n",
        "            total_batches = 0\n",
        "            processed_duration = 0\n",
        "\n",
        "        if existing_input_segments == 0:\n",
        "            print(f\"Splitting video into segments of {segment_duration} seconds...\")\n",
        "            segment_pattern = os.path.join(temp_dir, \"segment_%03d.mp4\")\n",
        "            cmd_split = [\n",
        "                \"ffmpeg\", \"-i\", file_name, \"-c\", \"copy\", \"-map\", \"0\",\n",
        "                \"-segment_time\", str(segment_duration), \"-f\", \"segment\",\n",
        "                \"-reset_timestamps\", \"1\", \"-y\", segment_pattern\n",
        "            ]\n",
        "            result_split = subprocess.run(cmd_split, capture_output=True, text=True)\n",
        "            if result_split.returncode != 0:\n",
        "                print(\"Error splitting video:\")\n",
        "                print(result_split.stderr)\n",
        "                raise subprocess.CalledProcessError(result_split.returncode, cmd_split)\n",
        "        segments = sorted([f for f in os.listdir(temp_dir) if f.startswith(\"segment_\") and f.endswith(\".mp4\")])\n",
        "        print(f\"Total segments to process: {len(segments)}\")\n",
        "\n",
        "        processed_segments = []\n",
        "        start_time = time.time()\n",
        "        # Determine the last processed segment from output_segments_dir and print it\n",
        "        output_files = [f for f in os.listdir(output_segments_dir) if f.startswith(\"final_segment_\") and f.endswith(f\"_{interpolation_factor}x.mp4\")]\n",
        "        processed_indices = set()\n",
        "        last_index = -1\n",
        "        if output_files:\n",
        "            segment_indices = []\n",
        "            for f in output_files:\n",
        "                parts = f.split(\"_\")\n",
        "                if len(parts) >= 3 and parts[2].isdigit():\n",
        "                    idx = int(parts[2])\n",
        "                    segment_indices.append(idx)\n",
        "            if segment_indices:\n",
        "                last_index = max(segment_indices)\n",
        "                processed_indices = set(segment_indices)\n",
        "                print(f\"Last processed segment: index {last_index}, file final_segment_{last_index}_{interpolation_factor}x.mp4\")\n",
        "            else:\n",
        "                print(\"No valid processed segments found in output_segments_dir\")\n",
        "        else:\n",
        "            print(\"No processed segments found in output_segments_dir\")\n",
        "\n",
        "        # Process all segments that exist and haven't been processed\n",
        "        segments_to_process = []\n",
        "        for s in segments:\n",
        "            try:\n",
        "                seg_index = int(s.split(\"_\")[1].split(\".\")[0])\n",
        "                output_file = os.path.join(output_segments_dir, f\"final_segment_{seg_index}_{interpolation_factor}x.mp4\")\n",
        "                if not os.path.exists(output_file) and os.path.exists(os.path.join(temp_dir, s)):\n",
        "                    segments_to_process.append((seg_index, s))\n",
        "            except (IndexError, ValueError):\n",
        "                continue\n",
        "        segments_to_process.sort()  # Process in order\n",
        "        if not segments_to_process:\n",
        "            print(\"No segments to process: all segments already have output files or are missing in temp_dir\")\n",
        "\n",
        "        for i, segment in segments_to_process:\n",
        "            segment_path = os.path.join(temp_dir, segment)\n",
        "            temp_output = f\"/content/processed_segment_{i}_{interpolation_factor}x.mp4\"\n",
        "            flavr_output = f\"/content/{segment.rsplit('.', 1)[0]}_{interpolation_factor}x.mp4\"\n",
        "            first_frame_video = f\"/content/first_frame_{i}.mp4\"\n",
        "            first_frame_dup = f\"/content/first_frame_dup_{i}.mp4\"\n",
        "            second_frame_video = f\"/content/second_frame_{i}.mp4\"\n",
        "            last_frame_video = f\"/content/last_frame_{i}.mp4\"\n",
        "            last_frame_dup = f\"/content/last_frame_dup_{i}.mp4\"\n",
        "            final_segment = os.path.join(output_segments_dir, f\"final_segment_{i}_{interpolation_factor}x.mp4\")\n",
        "\n",
        "            for f in [temp_output, flavr_output, first_frame_video, first_frame_dup, second_frame_video, last_frame_video, last_frame_dup]:\n",
        "                if os.path.exists(f):\n",
        "                    os.remove(f)\n",
        "\n",
        "            cap = cv2.VideoCapture(segment_path)\n",
        "            seg_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            seg_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            seg_duration = seg_frame_count / seg_fps\n",
        "            cap.release()\n",
        "            seg_output_fps = seg_fps * interpolation_factor\n",
        "            frame_duration = 1 / seg_output_fps\n",
        "            expected_seg_frame_count = seg_frame_count * interpolation_factor\n",
        "\n",
        "            logging.info(f\"Segment {i} input: FPS {seg_fps}, Frames {seg_frame_count}, Duration {seg_duration:.2f} sec\")\n",
        "            logging.info(f\"Segment {i} expected: FPS {seg_output_fps}, Frames {expected_seg_frame_count}, Duration {seg_duration:.2f} sec\")\n",
        "\n",
        "            cmd_extract_first = [\n",
        "                \"ffmpeg\", \"-i\", segment_path, \"-frames:v\", \"1\", \"-r\", str(int(seg_output_fps)),\n",
        "                \"-c:v\", \"libx264\", \"-c:a\", \"aac\", \"-t\", str(frame_duration), \"-y\", first_frame_video\n",
        "            ]\n",
        "            subprocess.run(cmd_extract_first, capture_output=True, text=True)\n",
        "            shutil.copy(first_frame_video, first_frame_dup)\n",
        "\n",
        "            cmd_extract_second = [\n",
        "                \"ffmpeg\", \"-i\", segment_path, \"-vf\", \"select='eq(n\\,1)'\",\n",
        "                \"-frames:v\", \"1\", \"-r\", str(int(seg_output_fps)), \"-c:v\", \"libx264\", \"-c:a\", \"aac\",\n",
        "                \"-t\", str(frame_duration), \"-y\", second_frame_video\n",
        "            ]\n",
        "            subprocess.run(cmd_extract_second, capture_output=True, text=True)\n",
        "\n",
        "            cmd_extract_last = [\n",
        "                \"ffmpeg\", \"-i\", segment_path, \"-vf\", f\"select='eq(n\\,{seg_frame_count-1})'\",\n",
        "                \"-frames:v\", \"1\", \"-r\", str(int(seg_output_fps)), \"-c:v\", \"libx264\", \"-c:a\", \"aac\",\n",
        "                \"-t\", str(frame_duration), \"-y\", last_frame_video\n",
        "            ]\n",
        "            subprocess.run(cmd_extract_last, capture_output=True, text=True)\n",
        "            shutil.copy(last_frame_video, last_frame_dup)\n",
        "\n",
        "            cmd_flavr = [\n",
        "                \"python\", \"/content/FLAVR/interpolate.py\",\n",
        "                \"--input_video\", str(segment_path),\n",
        "                \"--factor\", str(interpolation_factor),\n",
        "                \"--load_model\", str(model_path),\n",
        "                \"--output_fps\", str(int(seg_output_fps)),\n",
        "                \"--batch_size\", str(batch_size)\n",
        "            ]\n",
        "\n",
        "            flavr_start_time = time.time()\n",
        "            result_flavr = subprocess.run(cmd_flavr, capture_output=True, text=True)\n",
        "            flavr_time = time.time() - flavr_start_time\n",
        "            total_flavr_time += flavr_time\n",
        "\n",
        "            cap = cv2.VideoCapture(segment_path)\n",
        "            seg_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            groups = max(1, seg_frame_count - 4 + 1)\n",
        "            batches = (groups + batch_size - 1) // batch_size\n",
        "            total_batches += batches\n",
        "            processed_duration += seg_duration\n",
        "            cap.release()\n",
        "\n",
        "            with open(stats_file, 'w') as f:\n",
        "                json.dump({\n",
        "                    'total_flavr_time': total_flavr_time,\n",
        "                    'total_batches': total_batches,\n",
        "                    'processed_duration': processed_duration\n",
        "                }, f)\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "            progress = (i + 1) / len(segments)\n",
        "            if i > 0 and total_flavr_time > 0:\n",
        "                avg_flavr_time_per_segment = total_flavr_time / (i + 1)\n",
        "                remaining_segments = len(segments) - (i + 1)\n",
        "                remaining_time = avg_flavr_time_per_segment * remaining_segments\n",
        "            else:\n",
        "                remaining_time = 0\n",
        "            bar_length = 30\n",
        "            filled = int(bar_length * progress)\n",
        "            bar = '=' * filled + '-' * (bar_length - filled)\n",
        "            elapsed_str = f\"{int(elapsed_time // 60):02d}:{int(elapsed_time % 60):02d}\"\n",
        "            remaining_str = f\"{int(remaining_time // 60):02d}:{int(remaining_time % 60):02d}\"\n",
        "\n",
        "            if total_batches > 0 and processed_duration > 0 and i >= 0:\n",
        "                avg_time_per_batch = total_flavr_time / total_batches\n",
        "                avg_time_per_second = total_flavr_time / processed_duration\n",
        "                avg_time_per_segment = total_flavr_time / (i + 1)\n",
        "                avg_stats = f\"Avg time/batch (size={batch_size}): {avg_time_per_batch:.2f}s, Avg time/sec: {avg_time_per_second:.2f}s, Avg time/segment: {avg_time_per_segment:.2f}s\"\n",
        "            else:\n",
        "                avg_stats = \"Avg time/batch: N/A, Avg time/sec: N/A, Avg time/segment: N/A\"\n",
        "\n",
        "            sys.stdout.write(f\"\\rProcessing segment {i+1}/{len(segments)}: [{bar}] {progress:.1%} | Elapsed: {elapsed_str} | Remaining: {remaining_str} | {avg_stats}\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            if result_flavr.returncode != 0:\n",
        "                print(f\"\\nError processing segment {segment}:\")\n",
        "                print(result_flavr.stderr)\n",
        "                raise subprocess.CalledProcessError(result_flavr.returncode, cmd_flavr)\n",
        "            elif not os.path.exists(flavr_output):\n",
        "                print(f\"\\nError: FLAVR file not created: {flavr_output}\")\n",
        "                raise FileNotFoundError(f\"FLAVR output not created: {flavr_output}\")\n",
        "            else:\n",
        "                def move_with_retry(src, dst):\n",
        "                    if output_folder == \"google_drive\":\n",
        "                        for attempt in range(20):\n",
        "                            try:\n",
        "                                shutil.move(src, dst)\n",
        "                                return True\n",
        "                            except:\n",
        "                                if attempt < 19:\n",
        "                                    time.sleep(3)\n",
        "                                    continue\n",
        "                                print(f\"\\nFailed to move {src} after 20 attempts\")\n",
        "                                return False\n",
        "                    else:\n",
        "                        shutil.move(src, dst)\n",
        "                        return True\n",
        "\n",
        "                if move_with_retry(flavr_output, temp_output):\n",
        "                    cap = cv2.VideoCapture(temp_output)\n",
        "                    flavr_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                    flavr_duration = flavr_frame_count / seg_output_fps\n",
        "                    cap.release()\n",
        "                    logging.info(f\"Segment {i} after FLAVR: FPS {seg_output_fps}, Frames {flavr_frame_count}, Duration {flavr_duration:.2f} sec\")\n",
        "                    logging.info(f\"Segment {i} FLAVR frame difference (actual - expected): {flavr_frame_count - expected_seg_frame_count}\")\n",
        "\n",
        "                    concat_list_temp = f\"/content/concat_list_{i}.txt\"\n",
        "                    def write_concat_list():\n",
        "                        for attempt in range(20):\n",
        "                            try:\n",
        "                                with open(concat_list_temp, \"w\") as f:\n",
        "                                    f.write(f\"file '{first_frame_video}'\\n\")\n",
        "                                    f.write(f\"file '{first_frame_dup}'\\n\")\n",
        "                                    f.write(f\"file '{second_frame_video}'\\n\")\n",
        "                                    f.write(f\"file '{temp_output}'\\n\")\n",
        "                                    f.write(f\"file '{last_frame_dup}'\\n\")\n",
        "                                    f.write(f\"file '{last_frame_video}'\\n\")\n",
        "                                return True\n",
        "                            except:\n",
        "                                if attempt < 19:\n",
        "                                    time.sleep(3)\n",
        "                                    continue\n",
        "                                print(f\"\\nFailed to write concat list after 20 attempts\")\n",
        "                                return False\n",
        "\n",
        "                    if write_concat_list():\n",
        "                        cmd_concat_segment = [\n",
        "                            \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", concat_list_temp,\n",
        "                            \"-c:v\", \"libx264\", \"-b:v\", f\"{output_bitrate}\", \"-c:a\", \"aac\", \"-r\", str(int(seg_output_fps)), \"-y\", final_segment\n",
        "                        ]\n",
        "                        result_concat_seg = subprocess.run(cmd_concat_segment, capture_output=True, text=True)\n",
        "                        if result_concat_seg.returncode != 0:\n",
        "                            print(f\"\\nError concatenating segment {segment}:\")\n",
        "                            print(result_concat_seg.stderr)\n",
        "                            raise subprocess.CalledProcessError(result_concat_seg.returncode, cmd_concat_segment)\n",
        "\n",
        "                        cap = cv2.VideoCapture(final_segment)\n",
        "                        final_seg_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                        final_seg_duration = final_seg_frame_count / seg_output_fps\n",
        "                        cap.release()\n",
        "                        logging.info(f\"Segment {i} final: FPS {seg_output_fps}, Frames {final_seg_frame_count}, Duration {final_seg_duration:.2f} sec\")\n",
        "                        logging.info(f\"Segment {i} final frame difference (final - expected): {final_seg_frame_count - expected_seg_frame_count}\")\n",
        "                        logging.info(f\"Segment {i} duration difference (final - input): {final_seg_duration - seg_duration:.2f} sec\")\n",
        "                        processed_segments.append(final_segment)\n",
        "\n",
        "                        for f in [temp_output, first_frame_video, first_frame_dup, second_frame_video, last_frame_video, last_frame_dup, concat_list_temp]:\n",
        "                            if os.path.exists(f):\n",
        "                                os.remove(f)\n",
        "\n",
        "            gc.collect()\n",
        "\n",
        "        print(f\"\\nSegment processing complete. Processed segments saved in {output_segments_dir}\")"
      ],
      "metadata": {
        "id": "jKuz1FwFDs0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Create video** { display-mode: \"form\" }\n",
        "import subprocess\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "import re\n",
        "\n",
        "log_file = '/content/processing_log.txt'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO,\n",
        "                   format='%(asctime)s - %(message)s')\n",
        "\n",
        "\n",
        "if 'file_name' not in globals() or 'output_video' not in globals() or 'temp_output_video' not in globals() or 'output_fps' not in globals() or 'output_segments_dir' not in globals() or 'expected_frame_count' not in globals() or 'input_duration' not in globals():\n",
        "    print(\"Error: Required variables not defined. Run the 'Segment Processing' cell first.\")\n",
        "else:\n",
        "    print(\"Merging processed segments...\")\n",
        "\n",
        "    segment_files = [f for f in os.listdir(output_segments_dir) if f.endswith(\".mp4\")]\n",
        "    def get_segment_number(filename):\n",
        "        match = re.search(r'segment_(\\d+)', filename)\n",
        "        return int(match.group(1)) if match else float('inf')\n",
        "    processed_segments = sorted(\n",
        "        [os.path.join(output_segments_dir, f) for f in segment_files],\n",
        "        key=lambda x: get_segment_number(os.path.basename(x))\n",
        "    )\n",
        "    if not processed_segments:\n",
        "        print(f\"Error: No processed segments found in {output_segments_dir}\")\n",
        "        raise FileNotFoundError(\"No processed segments available\")\n",
        "\n",
        "    total_segment_frames = 0\n",
        "    total_segment_duration = 0\n",
        "    print(f\"Found {len(processed_segments)} segments to merge\")\n",
        "    logging.info(f\"Merging {len(processed_segments)} segments\")\n",
        "\n",
        "    for i, seg in enumerate(processed_segments):\n",
        "        cap = cv2.VideoCapture(seg)\n",
        "        seg_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        seg_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        seg_duration = seg_frame_count / seg_fps if seg_fps > 0 else 0\n",
        "        total_segment_frames += seg_frame_count\n",
        "        total_segment_duration += seg_duration\n",
        "        cap.release()\n",
        "        logging.info(f\"Segment {i} for merging: File {os.path.basename(seg)}, Frames {seg_frame_count}, FPS {seg_fps:.2f}, Duration {seg_duration:.2f} sec\")\n",
        "        print(f\"Segment {i}: File {os.path.basename(seg)}, Frames {seg_frame_count}, Duration {seg_duration:.2f} sec\")\n",
        "\n",
        "    logging.info(f\"Total before merging: Frames {total_segment_frames}, Duration {total_segment_duration:.2f} sec\")\n",
        "    print(f\"Total before merging: Frames {total_segment_frames}, Duration {total_segment_duration:.2f} sec\")\n",
        "\n",
        "    cmd_bitrate = [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=bit_rate\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", file_name]\n",
        "    result_bitrate = subprocess.run(cmd_bitrate, capture_output=True, text=True)\n",
        "    input_bitrate = int(result_bitrate.stdout.strip()) if result_bitrate.stdout.strip().isdigit() else 2000000\n",
        "    output_bitrate = input_bitrate * interpolation_factor\n",
        "    print(f\"Input bitrate: {input_bitrate / 1000:.0f} kbit/s, Target bitrate: {output_bitrate / 1000:.0f} kbit/s\")\n",
        "    logging.info(f\"Input bitrate: {input_bitrate / 1000:.0f} kbit/s, Target bitrate: {output_bitrate / 1000:.0f} kbit/s\")\n",
        "\n",
        "    concat_list = os.path.join(temp_dir, \"concat_list.txt\")\n",
        "    def write_final_concat_list():\n",
        "        for attempt in range(20):\n",
        "            try:\n",
        "                with open(concat_list, \"w\") as f:\n",
        "                    for seg in processed_segments:\n",
        "                        f.write(f\"file '{seg}'\\n\")\n",
        "                return True\n",
        "            except:\n",
        "                if attempt < 19:\n",
        "                    time.sleep(3)\n",
        "                    continue\n",
        "                print(f\"Failed to write final concat list after 20 attempts\")\n",
        "                logging.error(f\"Failed to write final concat list after 20 attempts\")\n",
        "                return False\n",
        "\n",
        "    if write_final_concat_list():\n",
        "        cmd_concat = [\n",
        "            \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", concat_list,\n",
        "            \"-c:v\", \"libx264\", \"-vsync\", \"0\", \"-copyts\",\n",
        "            \"-b:v\", f\"{output_bitrate}\", \"-an\", \"-sn\", \"-y\", temp_output_video\n",
        "        ]\n",
        "        result_concat = subprocess.run(cmd_concat, capture_output=True, text=True)\n",
        "        if result_concat.returncode != 0:\n",
        "            print(\"Error merging segments:\")\n",
        "            print(result_concat.stderr)\n",
        "            logging.error(f\"Error merging segments: {result_concat.stderr}\")\n",
        "            raise subprocess.CalledProcessError(result_concat.returncode, cmd_concat)\n",
        "\n",
        "        cap = cv2.VideoCapture(temp_output_video)\n",
        "        temp_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        temp_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        temp_duration = temp_frame_count / temp_fps if temp_fps > 0 else 0\n",
        "        cap.release()\n",
        "        logging.info(f\"Temp merged video: Frames {temp_frame_count}, FPS {temp_fps:.2f}, Duration {temp_duration:.2f} sec\")\n",
        "        logging.info(f\"Temp merged frame difference (actual - expected): {temp_frame_count - expected_frame_count}\")\n",
        "        logging.info(f\"Temp merged duration difference (actual - input): {temp_duration - input_duration:.2f} sec\")\n",
        "        print(f\"Temp merged video: Frames {temp_frame_count}, Diff from expected {temp_frame_count - expected_frame_count}, Duration {temp_duration:.2f} sec\")\n",
        "\n",
        "        cmd_final = [\n",
        "            \"ffmpeg\", \"-i\", temp_output_video, \"-i\", file_name,\n",
        "            \"-map\", \"0:v\", \"-map\", \"1:a?\", \"-map\", \"1:s?\",\n",
        "            \"-c:v\", \"libx264\", \"-vsync\", \"0\", \"-copyts\",\n",
        "            \"-b:v\", f\"{output_bitrate}\",\n",
        "            \"-c:a\", \"copy\", \"-c:s\", \"copy\", \"-y\", output_video\n",
        "        ]\n",
        "        result_final = subprocess.run(cmd_final, capture_output=True, text=True)\n",
        "        if result_final.returncode != 0:\n",
        "            print(\"Error in final merge:\")\n",
        "            print(result_final.stderr)\n",
        "            logging.error(f\"Error in final merge: {result_final.stderr}\")\n",
        "            raise subprocess.CalledProcessError(result_final.returncode, cmd_final)\n",
        "\n",
        "        cap = cv2.VideoCapture(output_video)\n",
        "        final_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        final_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        final_duration = final_frame_count / final_fps if final_fps > 0 else 0\n",
        "        cap.release()\n",
        "\n",
        "        cmd_audio_duration = [\n",
        "            \"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "            \"-of\", \"default=noprint_wrappers=1:nokey=1\", output_video\n",
        "        ]\n",
        "        result_audio_duration = subprocess.run(cmd_audio_duration, capture_output=True, text=True)\n",
        "        final_audio_duration = float(result_audio_duration.stdout.strip()) if result_audio_duration.stdout.strip() else 0\n",
        "\n",
        "        logging.info(f\"Final video: Frames {final_frame_count}, FPS {final_fps:.2f}, Video Duration {final_duration:.2f} sec, Audio Duration {final_audio_duration:.2f} sec\")\n",
        "        logging.info(f\"Final frame difference (final - expected): {final_frame_count - expected_frame_count}\")\n",
        "        logging.info(f\"Final video duration difference (final - input): {final_duration - input_duration:.2f} sec\")\n",
        "        logging.info(f\"Final audio-video duration difference: {final_audio_duration - final_duration:.2f} sec\")\n",
        "        print(f\"Final video: Frames {final_frame_count}, Diff from expected {final_frame_count - expected_frame_count}, Video Duration {final_duration:.2f} sec, Audio Duration {final_audio_duration:.2f} sec\")\n",
        "        print(f\"Duration differences: Video vs Input {final_duration - input_duration:.2f} sec, Audio vs Video {final_audio_duration - final_duration:.2f} sec\")"
      ],
      "metadata": {
        "id": "lwZV4Afst0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygvx7uenHMsG"
      },
      "outputs": [],
      "source": [
        "#@title ##**Compare videos (optional)** { display-mode: \"form\" }\n",
        "from IPython.display import display, HTML\n",
        "import os\n",
        "import base64\n",
        "\n",
        "original_video_path = file_name\n",
        "processed_video_path = output_video\n",
        "\n",
        "if not os.path.exists(original_video_path):\n",
        "    raise ValueError(f\"Оригинальное видео не найдено по пути: {original_video_path}\")\n",
        "if not os.path.exists(processed_video_path):\n",
        "    raise ValueError(f\"Обработанное видео не найдено по пути: {processed_video_path}\")\n",
        "\n",
        "original_size = os.path.getsize(original_video_path) / (1024 * 1024)\n",
        "processed_size = os.path.getsize(processed_video_path) / (1024 * 1024)\n",
        "print(f\"Размер оригинального видео: {original_size:.2f} МБ\")\n",
        "print(f\"Размер обработанного видео: {processed_size:.2f} МБ\")\n",
        "\n",
        "\n",
        "def video_to_base64(video_path):\n",
        "    with open(video_path, \"rb\") as video_file:\n",
        "        video_data = video_file.read()\n",
        "    return base64.b64encode(video_data).decode('utf-8')\n",
        "\n",
        "original_base64 = video_to_base64(original_video_path)\n",
        "processed_base64 = video_to_base64(processed_video_path)\n",
        "\n",
        "html_code = f\"\"\"\n",
        "<div style=\"display: flex; justify-content: center; flex-direction: column; align-items: center;\">\n",
        "    <div style=\"display: flex; justify-content: center;\">\n",
        "        <div style=\"margin-right: 10px;\">\n",
        "            <video id=\"originalVideo\" width=\"400\" controls preload=\"auto\">\n",
        "                <source src=\"data:video/mp4;base64,{original_base64}\" type=\"video/mp4\">\n",
        "                Ваш браузер не поддерживает видео.\n",
        "            </video>\n",
        "            <p>Оригинальное видео</p>\n",
        "        </div>\n",
        "        <div>\n",
        "            <video id=\"processedVideo\" width=\"400\" controls preload=\"auto\">\n",
        "                <source src=\"data:video/mp4;base64,{processed_base64}\" type=\"video/mp4\">\n",
        "                Ваш браузер не поддерживает видео.\n",
        "            </video>\n",
        "            <p>Обработанное видео</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    <button id=\"playPauseBtn\" style=\"margin-top: 10px; padding: 10px 20px; font-size: 16px;\">Play</button>\n",
        "</div>\n",
        "<script>\n",
        "(function() {{\n",
        "    var originalVideo = document.getElementById(\"originalVideo\");\n",
        "    var processedVideo = document.getElementById(\"processedVideo\");\n",
        "    var playPauseBtn = document.getElementById(\"playPauseBtn\");\n",
        "    var isPlaying = false;\n",
        "\n",
        "    playPauseBtn.disabled = false;\n",
        "\n",
        "    function playBoth() {{\n",
        "        Promise.all([\n",
        "            originalVideo.play().catch(function(error) {{\n",
        "                console.log(\"Ошибка воспроизведения оригинального видео:\", error);\n",
        "            }}),\n",
        "            processedVideo.play().catch(function(error) {{\n",
        "                console.log(\"Ошибка воспроизведения обработанного видео:\", error);\n",
        "            }})\n",
        "        ]).then(function() {{\n",
        "            playPauseBtn.textContent = \"Pause\";\n",
        "            isPlaying = true;\n",
        "        }}).catch(function(error) {{\n",
        "            console.log(\"Не удалось воспроизвести видео:\", error);\n",
        "        }});\n",
        "    }}\n",
        "\n",
        "    function pauseBoth() {{\n",
        "        originalVideo.pause();\n",
        "        processedVideo.pause();\n",
        "        playPauseBtn.textContent = \"Play\";\n",
        "        isPlaying = false;\n",
        "    }}\n",
        "\n",
        "    playPauseBtn.addEventListener(\"click\", function() {{\n",
        "        if (isPlaying) {{\n",
        "            pauseBoth();\n",
        "        }} else {{\n",
        "            playBoth();\n",
        "        }}\n",
        "    }});\n",
        "\n",
        "    originalVideo.addEventListener(\"play\", function() {{\n",
        "        if (processedVideo.paused) processedVideo.play();\n",
        "        playPauseBtn.textContent = \"Pause\";\n",
        "        isPlaying = true;\n",
        "    }});\n",
        "    processedVideo.addEventListener(\"play\", function() {{\n",
        "        if (originalVideo.paused) originalVideo.play();\n",
        "        playPauseBtn.textContent = \"Pause\";\n",
        "        isPlaying = true;\n",
        "    }});\n",
        "    originalVideo.addEventListener(\"pause\", function() {{\n",
        "        if (!processedVideo.paused) processedVideo.pause();\n",
        "        playPauseBtn.textContent = \"Play\";\n",
        "        isPlaying = false;\n",
        "    }});\n",
        "    processedVideo.addEventListener(\"pause\", function() {{\n",
        "        if (!originalVideo.paused) originalVideo.pause();\n",
        "        playPauseBtn.textContent = \"Play\";\n",
        "        isPlaying = false;\n",
        "    }});\n",
        "\n",
        "    originalVideo.addEventListener(\"timeupdate\", function() {{\n",
        "        if (Math.abs(originalVideo.currentTime - processedVideo.currentTime) > 0.5) {{\n",
        "            processedVideo.currentTime = originalVideo.currentTime;\n",
        "        }}\n",
        "    }});\n",
        "    processedVideo.addEventListener(\"timeupdate\", function() {{\n",
        "        if (Math.abs(processedVideo.currentTime - originalVideo.currentTime) > 0.5) {{\n",
        "            originalVideo.currentTime = processedVideo.currentTime;\n",
        "        }}\n",
        "    }});\n",
        "\n",
        "    console.log(\"Скрипт синхронизации видео инициализирован\");\n",
        "}})();\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_code))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Compare frames (optional)** { display-mode: \"form\" }\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display, Image\n",
        "\n",
        "max_frames_to_show = 3 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "\n",
        "if 'file_name' not in globals() or file_name is None or not os.path.exists(file_name):\n",
        "    print(\"Error: Original video file is not selected or does not exist.\")\n",
        "elif 'output_video' not in globals() or not os.path.exists(output_video):\n",
        "    print(\"Error: Interpolated video file not found. Run the 'Run' cell first.\")\n",
        "else:\n",
        "    cap_orig = cv2.VideoCapture(file_name)\n",
        "    cap_interp = cv2.VideoCapture(output_video)\n",
        "\n",
        "    if not cap_orig.isOpened() or not cap_interp.isOpened():\n",
        "        print(\"Error: Could not open one or both video files.\")\n",
        "    else:\n",
        "        print(f\"Building frame comparison strip for original ({file_name}) and interpolated ({output_video}) videos:\")\n",
        "        print(f\"Interpolation factor: {interpolation_factor}\")\n",
        "\n",
        "        orig_frame_count = int(cap_orig.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        interp_frame_count = int(cap_interp.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        max_orig_frames = min(max_frames_to_show, orig_frame_count)\n",
        "        max_interp_frames = min(max_orig_frames * interpolation_factor, interp_frame_count)\n",
        "\n",
        "        frame_width, frame_height = 640, 360\n",
        "\n",
        "        orig_frames = []\n",
        "        interp_frames = []\n",
        "\n",
        "        from PIL import ImageDraw, ImageFont\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"DejaVuSans.ttf\", 30)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        for orig_frame_num in range(max_orig_frames):\n",
        "            ret_orig, frame_orig = cap_orig.read()\n",
        "            if not ret_orig:\n",
        "                print(f\"Error reading original frame {orig_frame_num}\")\n",
        "                break\n",
        "            frame_orig_rgb = cv2.cvtColor(frame_orig, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = PILImage.fromarray(frame_orig_rgb).resize((frame_width, frame_height))\n",
        "            draw = ImageDraw.Draw(pil_img)\n",
        "            draw.text((10, frame_height-40), f\"#{orig_frame_num}\", fill=\"white\", font=font)\n",
        "            orig_frames.append(pil_img)\n",
        "\n",
        "        for interp_frame_num in range(max_interp_frames):\n",
        "            ret_interp, frame_interp = cap_interp.read()\n",
        "            if not ret_interp:\n",
        "                print(f\"Error reading interpolated frame {interp_frame_num}\")\n",
        "                break\n",
        "            frame_interp_rgb = cv2.cvtColor(frame_interp, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = PILImage.fromarray(frame_interp_rgb).resize((frame_width, frame_height))\n",
        "            draw = ImageDraw.Draw(pil_img)\n",
        "            draw.text((10, frame_height-40), f\"#{interp_frame_num}\", fill=\"white\", font=font)\n",
        "            interp_frames.append(pil_img)\n",
        "\n",
        "        cap_orig.release()\n",
        "        cap_interp.release()\n",
        "\n",
        "        blank_frame = PILImage.new('RGB', (frame_width, frame_height), color='black')\n",
        "        draw_blank = ImageDraw.Draw(blank_frame)\n",
        "        draw_blank.text((10, frame_height-40), \"#N/A\", fill=\"white\", font=font)\n",
        "\n",
        "        orig_strip_frames = []\n",
        "        for i in range(max_interp_frames):\n",
        "            if i % interpolation_factor == 0 and i // interpolation_factor < len(orig_frames):\n",
        "                orig_strip_frames.append(orig_frames[i // interpolation_factor])\n",
        "            else:\n",
        "                orig_strip_frames.append(blank_frame.copy())\n",
        "\n",
        "        try:\n",
        "            num_frames = min(len(orig_strip_frames), len(interp_frames))\n",
        "\n",
        "            orig_strip = PILImage.new('RGB', (frame_width * num_frames, frame_height))\n",
        "            interp_strip = PILImage.new('RGB', (frame_width * num_frames, frame_height))\n",
        "\n",
        "            for i in range(num_frames):\n",
        "                x_offset = i * frame_width\n",
        "                if i < len(orig_strip_frames):\n",
        "                    orig_strip.paste(orig_strip_frames[i], (x_offset, 0))\n",
        "                if i < len(interp_frames):\n",
        "                    interp_strip.paste(interp_frames[i], (x_offset, 0))\n",
        "\n",
        "            comparison_strip = PILImage.new('RGB', (frame_width * num_frames, frame_height * 2))\n",
        "            comparison_strip.paste(orig_strip, (0, 0))\n",
        "            comparison_strip.paste(interp_strip, (0, frame_height))\n",
        "\n",
        "            draw = ImageDraw.Draw(comparison_strip)\n",
        "            try:\n",
        "                font = ImageFont.truetype(\"DejaVuSans.ttf\", 20)\n",
        "            except:\n",
        "                font = ImageFont.load_default()\n",
        "\n",
        "            draw.text((10, 10), \"Original video\", fill=\"white\", font=font)\n",
        "            draw.text((10, frame_height + 10), \"Interpolated video\", fill=\"white\", font=font)\n",
        "\n",
        "            strip_path = \"/content/comparison_strip.jpg\"\n",
        "            comparison_strip.save(strip_path)\n",
        "\n",
        "            print(\"\\nOriginal frames (top) vs Interpolated frames (bottom):\")\n",
        "            display(Image(filename=strip_path))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating comparison image: {str(e)}\")\n",
        "\n",
        "        print(\"\\nFrame comparison strip completed.\")"
      ],
      "metadata": {
        "id": "0brG3j6YvXt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt5xhPHGk3Vp"
      },
      "outputs": [],
      "source": [
        "#@title ##**Download** { display-mode: \"form\" }\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if os.path.exists(output_video):\n",
        "    print(f\"Stabilized video saved at: {output_video}\")\n",
        "    files.download(output_video)\n",
        "else:\n",
        "    print(\"Error: Stabilized video was not created.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}